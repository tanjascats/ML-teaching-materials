# ML teaching materials

## Algotithm demos
- [Streamlit playground with multiple algorithms](https://share.streamlit.io/ahmedbesbes/playground/main/app.py) ([source](https://github.com/ahmedbesbes/playground))
  - model types: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, Neural Network, K Nearest Neighbors, Gaussian Naive Bayes, SVC
  - demo of decision boundary, accuracy/F1 score on test set, general tips on algorithms
  - hyperparameter influence, dataset distribution influence

### KNN
- [algorithm steps](https://adotg.github.io/knn-what-how-why/)
- [influence of the hyperparameters](http://vision.stanford.edu/teaching/cs231n-demos/knn/)
- [decision boundary](https://martin-thoma.com/k-nearest-neighbor-classification-interactive-example/)

### Decision Tree
- [great visuals for intuition on building the DTs](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)
- [demo with Jupyter widgets](https://towardsdatascience.com/interactive-visualization-of-decision-trees-with-jupyter-widgets-ca15dd312084)

### Gradient Boosting 
- [Regression](https://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)
- [Classification](http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html)
- [StatQuest](https://www.youtube.com/results?search_query=statquest+gradient+boosting) - the whole YT channel has good videos

### Random Forest
- [by Andrej Karpathy](https://cs.stanford.edu/~karpathy/svmjs/demo/demoforest.html)

### SVM
- [by Andrej Karpathy](https://cs.stanford.edu/people/karpathy/svmjs/demo/)

### Linear and Logistic Regression
- [calculator](https://www.desmos.com/calculator/naf1qogfjn)
- [gradient descent demo](https://share.streamlit.io/christopherdavisuci/streamlit_ed/main/grad_desc.py)
- [linear regression](https://colab.research.google.com/github/CC-MNNIT/2018-19-Classes/blob/master/MachineLearning/2018_08_22_Logical-Rhythm-2/linear_regression.ipynb#scrollTo=pHGbi8nY-eqI)
- [gradient descent](https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21#:~:text=Gradient%20descent%20(GD)%20is%20an,e.g.%20in%20a%20linear%20regression) - nice mathematical exmplanation; contains examples of a trajectory of parameters depending on different learning rates

### Perceptron
- [Perceptron](https://developpaper.com/perceptron-tutorial-implementation-and-visual-examples/)
- [Iteration animation](https://phiresky.github.io/kogsys-demos/neural-network-demo/?preset=Rosenblatt+Perceptron)

### NNs
- [by Andrej Karpathy](https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html)
- [Tensorflow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.05852&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)
- [phiresky@github](phiresky.github.io/neural-network-demo/)
- [CNN explainer](https://poloclub.github.io/cnn-explainer/)
- [DL tutorial by Thomas Lidy](https://github.com/audiofeature/DeepLearningTutorial_2019)

### Other (blogs, etc.)
- [Brilliantly wrong](http://arogozhnikov.github.io/2016/04/28/demonstrations-for-ml-courses.html)
- [R2D3](http://www.r2d3.us/)
- [Hyperparameter optimisation app](https://share.streamlit.io/dataprofessor/ml-opt-app/main/ml-opt-app.py)


